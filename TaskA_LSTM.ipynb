{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4a5ad83f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import keras\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import TextVectorization\n",
    "from keras.models import Sequential\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "640fc742",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Download dataset SubtaskA.jsonl from \n",
    "https://github.com/mbzuai-nlp/M4GT-Bench.\n",
    "\"\"\"\n",
    "DATA_PATH = \"C:/Users/Admin/Downloads/SubtaskA.jsonl\"\n",
    "\n",
    "# initialize dataframe\n",
    "df = pd.read_json(DATA_PATH, lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cbb3381e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "source\n",
      "wikihow      36556\n",
      "reddit       33999\n",
      "arxiv        33998\n",
      "wikipedia    31365\n",
      "peerread     16891\n",
      "Name: count, dtype: int64\n",
      "\n",
      "model\n",
      "human      65177\n",
      "chatGPT    16892\n",
      "gpt4       14344\n",
      "davinci    14340\n",
      "bloomz     14332\n",
      "dolly      14046\n",
      "cohere     13678\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df.source.value_counts())\n",
    "print()\n",
    "print(df.model.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d028b763",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model\n",
      "human    65177\n",
      "Name: count, dtype: int64\n",
      "\n",
      "model\n",
      "chatGPT    16892\n",
      "gpt4       14344\n",
      "davinci    14340\n",
      "bloomz     14332\n",
      "dolly      14046\n",
      "cohere     13678\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df[df.label == 0].model.value_counts())\n",
    "print()\n",
    "print(df[df.label == 1].model.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cbf69435",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>We consider a system of many polymers in solut...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>We present a catalog of 66 YSOs in the Serpens...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Spectroscopic Observations of the Intermediate...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>We present a new class of stochastic Lie group...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ALMA as the ideal probe of the solar chromosph...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152804</th>\n",
       "      <td>The main results presented in this dissertati...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152805</th>\n",
       "      <td>Fine-grained sketch-based image retrieval (FG...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152806</th>\n",
       "      <td>We present the derivation of the NNLO two-par...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152807</th>\n",
       "      <td>The principle of optimism in the face of unce...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152808</th>\n",
       "      <td>We consider the setting of prediction with ex...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>152809 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text  label\n",
       "0       We consider a system of many polymers in solut...      1\n",
       "1       We present a catalog of 66 YSOs in the Serpens...      1\n",
       "2       Spectroscopic Observations of the Intermediate...      1\n",
       "3       We present a new class of stochastic Lie group...      1\n",
       "4       ALMA as the ideal probe of the solar chromosph...      1\n",
       "...                                                   ...    ...\n",
       "152804   The main results presented in this dissertati...      0\n",
       "152805   Fine-grained sketch-based image retrieval (FG...      0\n",
       "152806   We present the derivation of the NNLO two-par...      0\n",
       "152807   The principle of optimism in the face of unce...      0\n",
       "152808   We consider the setting of prediction with ex...      0\n",
       "\n",
       "[152809 rows x 2 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['text', 'label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5e8472a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Pre-process dataframe.\n",
    "\"\"\"\n",
    "MAX_VOCAB = 10_000\n",
    "MAX_LENGTH = 200\n",
    "\n",
    "# init text vectorizer\n",
    "vectorize_layer = TextVectorization(\n",
    "    max_tokens=MAX_VOCAB,\n",
    "    standardize='lower_and_strip_punctuation',\n",
    "    split='whitespace',\n",
    "    ngrams=None,\n",
    "    output_mode='int',\n",
    "    output_sequence_length=MAX_LENGTH,\n",
    "    pad_to_max_tokens=False,\n",
    "    vocabulary=None,\n",
    "    idf_weights=None,\n",
    "    sparse=False,\n",
    "    ragged=False,\n",
    "    encoding='utf-8',\n",
    "    name=None,\n",
    ")\n",
    "\n",
    "# create vocabulary\n",
    "vectorize_layer.adapt(df['text'])\n",
    "vocab = vectorize_layer.get_vocabulary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e8f5cff1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(152809, 200) (152809,)\n"
     ]
    }
   ],
   "source": [
    "# vectorize text data (in subsets for memory constraints)\n",
    "X = []\n",
    "y = df['label']\n",
    "\n",
    "subset_size = df.shape[0] // 100\n",
    "for i in range(0, df.shape[0], subset_size):\n",
    "    subset = df['text'][i : i + subset_size]\n",
    "    X.append(vectorize_layer(subset))\n",
    "\n",
    "X = np.vstack(X)\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0d5e8b5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "LSTM model generator.\n",
    "\"\"\"\n",
    "EMBEDDING_DIM = 128\n",
    "N_HIDDEN = 100\n",
    "OPTIMIZER = 'adam'\n",
    "N_CLASSES = 2\n",
    "\n",
    "def get_model(model_path=None):\n",
    "    if model_path:\n",
    "        # load existing model\n",
    "        model = keras.models.load_model(model_path)\n",
    "    else:\n",
    "        # create new model\n",
    "        model = Sequential()\n",
    "        embeddings = Embedding(\n",
    "            input_dim=MAX_VOCAB,\n",
    "            output_dim=EMBEDDING_DIM,\n",
    "        )\n",
    "        model.add(embeddings)\n",
    "        model.add(LSTM(N_HIDDEN, return_sequences=False))\n",
    "        model.add(Dense(N_CLASSES)) # , activation='softmax'\n",
    "        model.compile(\n",
    "            loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "            optimizer=OPTIMIZER,\n",
    "            metrics=['accuracy']\n",
    "        )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4d605323",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m2030/2030\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m370s\u001b[0m 181ms/step - accuracy: 0.7507 - loss: 0.5110\n",
      "Epoch 2/5\n",
      "\u001b[1m2030/2030\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m367s\u001b[0m 181ms/step - accuracy: 0.8752 - loss: 0.3056\n",
      "Epoch 3/5\n",
      "\u001b[1m2030/2030\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m368s\u001b[0m 181ms/step - accuracy: 0.9035 - loss: 0.2410\n",
      "Epoch 4/5\n",
      "\u001b[1m2030/2030\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m366s\u001b[0m 180ms/step - accuracy: 0.9293 - loss: 0.1850\n",
      "Epoch 5/5\n",
      "\u001b[1m2030/2030\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m363s\u001b[0m 179ms/step - accuracy: 0.9453 - loss: 0.1446\n",
      "Accuracy: 88.61%\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Train and evaluate model.\n",
    "\"\"\"\n",
    "# create new model\n",
    "model = get_model()\n",
    "\n",
    "# create data splits\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X,\n",
    "    y,\n",
    "    test_size=0.15,\n",
    "    random_state=777,\n",
    ")\n",
    "\n",
    "# train the model\n",
    "model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    epochs=5,\n",
    "    batch_size=64\n",
    ")\n",
    "\n",
    "# final evaluation of the model\n",
    "scores = model.evaluate(\n",
    "    X_test,\n",
    "    y_test,\n",
    "    verbose=0\n",
    ")\n",
    "accuracy = scores[1]\n",
    "\n",
    "# report results\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100))\n",
    "\n",
    "# save model\n",
    "model.save(\"models/taskA_lstm.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a8dae301",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
