{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "52ed01ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch\n"
     ]
    }
   ],
   "source": [
    "import keras.backend as K\n",
    "\n",
    "print(K.backend())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4a5ad83f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import keras\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import TextVectorization\n",
    "from keras.models import Sequential\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "640fc742",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Download dataset SubtaskA.jsonl from \n",
    "https://github.com/mbzuai-nlp/M4GT-Bench.\n",
    "\n",
    "Google drive from repo: https://drive.google.com/drive/folders/1hBgW6sgZfz1BK0lVdUu0bZ4HPKSpOMSY\n",
    "Direct link to SubtaskA.jsonl: https://drive.google.com/file/d/1zwSfSKe4-0m2td_cP0Sl2LhKtksvtHlf/view\n",
    "\"\"\"\n",
    "import gdown, os\n",
    "# DATA_PATH = \"C:/Users/Admin/Downloads/SubtaskA.jsonl\"\n",
    "DATA_PATH = \"./datasets/SubtaskA.jsonl\"\n",
    "if not os.path.exists(DATA_PATH):\n",
    "    if not os.path.exists(os.path.dirname(DATA_PATH)):\n",
    "        os.makedirs(os.path.dirname(DATA_PATH))\n",
    "    gdown.download(\"https://drive.google.com/uc?id=1zwSfSKe4-0m2td_cP0Sl2LhKtksvtHlf\", DATA_PATH, quiet=False)\n",
    "\n",
    "# initialize dataframe\n",
    "df = pd.read_json(DATA_PATH, lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cbb3381e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wikihow      36556\n",
      "reddit       33999\n",
      "arxiv        33998\n",
      "wikipedia    31365\n",
      "peerread     16891\n",
      "Name: source, dtype: int64\n",
      "\n",
      "human      65177\n",
      "chatGPT    16892\n",
      "gpt4       14344\n",
      "davinci    14340\n",
      "bloomz     14332\n",
      "dolly      14046\n",
      "cohere     13678\n",
      "Name: model, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df.source.value_counts())\n",
    "print()\n",
    "print(df.model.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d028b763",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "human    65177\n",
      "Name: model, dtype: int64\n",
      "\n",
      "chatGPT    16892\n",
      "gpt4       14344\n",
      "davinci    14340\n",
      "bloomz     14332\n",
      "dolly      14046\n",
      "cohere     13678\n",
      "Name: model, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df[df.label == 0].model.value_counts())\n",
    "print()\n",
    "print(df[df.label == 1].model.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cbf69435",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>We consider a system of many polymers in solut...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>We present a catalog of 66 YSOs in the Serpens...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Spectroscopic Observations of the Intermediate...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>We present a new class of stochastic Lie group...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ALMA as the ideal probe of the solar chromosph...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152804</th>\n",
       "      <td>The main results presented in this dissertati...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152805</th>\n",
       "      <td>Fine-grained sketch-based image retrieval (FG...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152806</th>\n",
       "      <td>We present the derivation of the NNLO two-par...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152807</th>\n",
       "      <td>The principle of optimism in the face of unce...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152808</th>\n",
       "      <td>We consider the setting of prediction with ex...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>152809 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text  label\n",
       "0       We consider a system of many polymers in solut...      1\n",
       "1       We present a catalog of 66 YSOs in the Serpens...      1\n",
       "2       Spectroscopic Observations of the Intermediate...      1\n",
       "3       We present a new class of stochastic Lie group...      1\n",
       "4       ALMA as the ideal probe of the solar chromosph...      1\n",
       "...                                                   ...    ...\n",
       "152804   The main results presented in this dissertati...      0\n",
       "152805   Fine-grained sketch-based image retrieval (FG...      0\n",
       "152806   We present the derivation of the NNLO two-par...      0\n",
       "152807   The principle of optimism in the face of unce...      0\n",
       "152808   We consider the setting of prediction with ex...      0\n",
       "\n",
       "[152809 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['text', 'label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5e8472a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Pre-process dataframe.\n",
    "\"\"\"\n",
    "MAX_VOCAB = 10_000\n",
    "MAX_LENGTH = 200\n",
    "\n",
    "# init text vectorizer\n",
    "vectorize_layer = TextVectorization(\n",
    "    max_tokens=MAX_VOCAB,\n",
    "    standardize='lower_and_strip_punctuation',\n",
    "    split='whitespace',\n",
    "    ngrams=None,\n",
    "    output_mode='int',\n",
    "    output_sequence_length=MAX_LENGTH,\n",
    "    pad_to_max_tokens=False,\n",
    "    vocabulary=None,\n",
    "    idf_weights=None,\n",
    "    sparse=False,\n",
    "    ragged=False,\n",
    "    encoding='utf-8',\n",
    "    name=None,\n",
    ")\n",
    "\n",
    "# create vocabulary\n",
    "vectorize_layer.adapt(df['text'])\n",
    "vocab = vectorize_layer.get_vocabulary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e8f5cff1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(152809, 200) (152809,)\n"
     ]
    }
   ],
   "source": [
    "# vectorize text data (in subsets for memory constraints)\n",
    "X = []\n",
    "y = df['label']\n",
    "\n",
    "subset_size = df.shape[0] // 100\n",
    "for i in range(0, df.shape[0], subset_size):\n",
    "    subset = df['text'][i : i + subset_size]\n",
    "    X.append(vectorize_layer(subset).cpu())\n",
    "\n",
    "X = np.vstack(X)\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0d5e8b5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "LSTM model generator.\n",
    "\"\"\"\n",
    "EMBEDDING_DIM = 128\n",
    "N_HIDDEN = 100\n",
    "N_CLASSES = 2\n",
    "\n",
    "import torch\n",
    "class LSTMModel(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        self.embeddings = torch.nn.Embedding(\n",
    "            num_embeddings=MAX_VOCAB,\n",
    "            embedding_dim=EMBEDDING_DIM,\n",
    "        )\n",
    "        self.lstm = torch.nn.LSTM(\n",
    "            input_size=EMBEDDING_DIM,\n",
    "            hidden_size=N_HIDDEN,\n",
    "            num_layers=1,\n",
    "            batch_first=True,\n",
    "        )\n",
    "        self.linear = torch.nn.Linear(N_HIDDEN, N_CLASSES)\n",
    "        self.softmax = torch.nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embeddings(x)\n",
    "        x, _ = self.lstm(x)\n",
    "        x = self.linear(x[:, -1, :])\n",
    "        x = self.softmax(x)\n",
    "        return x\n",
    "    \n",
    "    def save(self, model_path):\n",
    "        torch.save(self.state_dict(), model_path)\n",
    "\n",
    "    def load(self, model_path):\n",
    "        self.load_state_dict(torch.load(model_path, weights_only=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "159f46d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def evaluate(model, loader):\n",
    "    model.eval()\n",
    "    loss = acc = 0\n",
    "    with torch.no_grad():\n",
    "        for X_batch, y_batch in loader:\n",
    "            y_pred = model(X_batch)\n",
    "            loss += model.loss_fn(y_pred, y_batch).item()\n",
    "            acc += (y_pred.argmax(1) == y_batch).sum().item()\n",
    "    return loss / len(loader), acc / len(loader.dataset)\n",
    "\n",
    "def train(model, train_loader, val_loader, epochs, save_best=False):\n",
    "    t_loss = t_acc = v_loss = v_acc = best_v_loss = best_v_acc = 0\n",
    "    def get_postfix():\n",
    "        return f\"train loss: {t_loss:.3f}, acc: {t_acc * 100:.2f}% \\\n",
    "| val loss: {v_loss:.3f}, acc: {v_acc * 100:.2f}% \\\n",
    "| best val loss: {best_v_loss:.3f}, acc: {best_v_acc * 100:.2f}%\"\n",
    "\n",
    "    best_v_loss = float('inf')\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        total_train_loss = total_train_correct = 0\n",
    "        with tqdm(train_loader, desc=f\"Epoch {epoch + 1}\") as pbar:\n",
    "            for i, (X_batch, y_batch) in enumerate(train_loader):\n",
    "                model.optimizer.zero_grad()\n",
    "                y_pred = model(X_batch)\n",
    "                loss = model.loss_fn(y_pred, y_batch)\n",
    "                loss.backward()\n",
    "                model.optimizer.step()\n",
    "\n",
    "                batch_loss, num_correct = loss.item(), (y_pred.argmax(1) == y_batch).sum().item()\n",
    "                total_train_loss += batch_loss\n",
    "                total_train_correct += num_correct\n",
    "\n",
    "                num_samples = (i + 1) * len(X_batch)\n",
    "                t_loss = total_train_loss / num_samples\n",
    "                t_acc = total_train_correct / num_samples\n",
    "                \n",
    "                pbar.set_postfix_str(get_postfix())\n",
    "                pbar.update()\n",
    "\n",
    "            t_loss = total_train_loss / len(train_loader)\n",
    "            t_acc = total_train_correct / len(train_loader.dataset)\n",
    "\n",
    "            v_loss, v_acc = evaluate(model, val_loader)\n",
    "\n",
    "            if save_best and v_loss < best_v_loss:\n",
    "                best_v_loss = v_loss\n",
    "                best_v_acc = v_acc\n",
    "                model.save(\"best_model.pth\")\n",
    "\n",
    "            pbar.set_postfix_str(get_postfix())\n",
    "            pbar.update()\n",
    "\n",
    "\n",
    "    # load best model\n",
    "    if save_best:\n",
    "        model.load(\"best_model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "59638d41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train LSTM model\n",
    "model = LSTMModel()\n",
    "model.optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-7)\n",
    "model.loss_fn = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bc32c2ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 766it [00:18, 40.77it/s, train loss: 0.645, acc: 63.75% | val loss: 0.625, acc: 67.26% | best val loss: 0.625, acc: 67.26%]                         \n",
      "Epoch 2: 766it [00:17, 42.71it/s, train loss: 0.580, acc: 71.82% | val loss: 0.562, acc: 73.78% | best val loss: 0.562, acc: 73.78%]                           \n",
      "Epoch 3: 766it [00:19, 39.74it/s, train loss: 0.576, acc: 72.15% | val loss: 0.542, acc: 76.22% | best val loss: 0.542, acc: 76.22%]                           \n",
      "Epoch 4: 766it [00:19, 39.34it/s, train loss: 0.515, acc: 79.14% | val loss: 0.501, acc: 80.43% | best val loss: 0.501, acc: 80.43%]                           \n",
      "Epoch 5: 766it [00:19, 39.30it/s, train loss: 0.484, acc: 82.37% | val loss: 0.480, acc: 82.74% | best val loss: 0.480, acc: 82.74%]                           \n",
      "Epoch 6: 766it [00:19, 39.27it/s, train loss: 0.466, acc: 84.38% | val loss: 0.472, acc: 83.59% | best val loss: 0.472, acc: 83.59%]                           \n",
      "Epoch 7: 766it [00:19, 39.16it/s, train loss: 0.452, acc: 85.80% | val loss: 0.460, acc: 84.79% | best val loss: 0.460, acc: 84.79%]                           \n",
      "Epoch 8: 766it [00:19, 39.24it/s, train loss: 0.439, acc: 87.08% | val loss: 0.453, acc: 85.56% | best val loss: 0.453, acc: 85.56%]                           \n",
      "Epoch 9: 766it [00:19, 39.18it/s, train loss: 0.428, acc: 88.18% | val loss: 0.445, acc: 86.31% | best val loss: 0.445, acc: 86.31%]                           \n",
      "Epoch 10: 766it [00:19, 39.12it/s, train loss: 0.417, acc: 89.38% | val loss: 0.444, acc: 86.49% | best val loss: 0.444, acc: 86.49%]                           \n",
      "Epoch 11: 766it [00:19, 39.14it/s, train loss: 0.409, acc: 90.23% | val loss: 0.435, acc: 87.36% | best val loss: 0.435, acc: 87.36%]                           \n",
      "Epoch 12: 766it [00:19, 38.53it/s, train loss: 0.401, acc: 90.98% | val loss: 0.431, acc: 87.80% | best val loss: 0.431, acc: 87.80%]                           \n",
      "Epoch 13: 766it [00:19, 39.08it/s, train loss: 0.393, acc: 91.93% | val loss: 0.432, acc: 87.70% | best val loss: 0.431, acc: 87.80%]                           \n",
      "Epoch 14: 766it [00:19, 38.46it/s, train loss: 0.389, acc: 92.39% | val loss: 0.429, acc: 88.05% | best val loss: 0.429, acc: 88.05%]                           \n",
      "Epoch 15: 766it [00:19, 38.32it/s, train loss: 0.384, acc: 92.84% | val loss: 0.427, acc: 88.17% | best val loss: 0.427, acc: 88.17%]                           \n",
      "Epoch 16: 766it [00:19, 38.89it/s, train loss: 0.379, acc: 93.36% | val loss: 0.426, acc: 88.31% | best val loss: 0.426, acc: 88.31%]                           \n",
      "Epoch 17: 766it [00:19, 38.98it/s, train loss: 0.377, acc: 93.59% | val loss: 0.425, acc: 88.42% | best val loss: 0.425, acc: 88.42%]                           \n",
      "Epoch 18: 766it [00:19, 39.21it/s, train loss: 0.375, acc: 93.81% | val loss: 0.424, acc: 88.57% | best val loss: 0.424, acc: 88.57%]                           \n",
      "Epoch 19: 766it [00:19, 39.17it/s, train loss: 0.370, acc: 94.38% | val loss: 0.425, acc: 88.45% | best val loss: 0.424, acc: 88.57%]                           \n",
      "Epoch 20: 766it [00:20, 37.77it/s, train loss: 0.368, acc: 94.50% | val loss: 0.424, acc: 88.58% | best val loss: 0.424, acc: 88.57%]                           \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.427, acc: 88.36%\n"
     ]
    }
   ],
   "source": [
    "# Prep data and train model\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "X_train = torch.tensor(X_train, dtype=torch.long)\n",
    "X_val = torch.tensor(X_val, dtype=torch.long)\n",
    "X_test = torch.tensor(X_test, dtype=torch.long)\n",
    "y_train = torch.tensor(y_train.values, dtype=torch.long)\n",
    "y_val = torch.tensor(y_val.values, dtype=torch.long)\n",
    "y_test = torch.tensor(y_test.values, dtype=torch.long)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "X_train = X_train.to(device)\n",
    "X_val = X_val.to(device)\n",
    "X_test = X_test.to(device)\n",
    "y_train = y_train.to(device)\n",
    "y_val = y_val.to(device)\n",
    "y_test = y_test.to(device)\n",
    "\n",
    "BATCH_SIZE = 128\n",
    "train_loader = torch.utils.data.DataLoader(torch.utils.data.TensorDataset(X_train, y_train), batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader = torch.utils.data.DataLoader(torch.utils.data.TensorDataset(X_val, y_val), batch_size=BATCH_SIZE, shuffle=False)\n",
    "test_loader = torch.utils.data.DataLoader(torch.utils.data.TensorDataset(X_test, y_test), batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "train(model, train_loader, val_loader, epochs=20, save_best=True)\n",
    "test_loss, test_acc = evaluate(model, test_loader)\n",
    "print(f\"Test loss: {test_loss:.3f}, acc: {test_acc * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "983fef5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "1\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ssit5\\AppData\\Local\\Temp\\ipykernel_5224\\443312697.py:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  text = torch.tensor(text).to(device)\n"
     ]
    }
   ],
   "source": [
    "def predict(text: str):\n",
    "    text = vectorize_layer([text]).cpu()\n",
    "    text = torch.tensor(text).to(device)\n",
    "    model.eval()\n",
    "    y_pred = model(text)\n",
    "    return y_pred.argmax(dim=1).item()\n",
    "\n",
    "# Human text\n",
    "print(predict(\"That's a reasonable hypothesis, and I tried that too. However the default resolvers are not returned but clearly they have to be there behind the scenes are the API wouldn't work. This is a bit of a flaky area. Wow -- even weirder. What you have to do is manually attach a resolver for each field on the type. So the default resolvers show up in the UI, and once you attach them you can export them. But again, those defaults had to be there originally. This is one of the more half-baked AWS services I've dealt with. It's good to work with the new ones ;).\"))\n",
    "print(predict(\"Although it is generally accepted that the internet has allowed us to connect with people all over the world, there are still those people who are not familiar with its basic functions, who don’t understand why it has become so commonplace, or what its true capabilities are.\"))\n",
    "\n",
    "# AI generated text\n",
    "print(predict(\"1. Eat a balanced and nutritious diet: Make sure your meals are inclusive of a variety of fruits and vegetables, lean protein, whole grains, and healthy fats. This helps to provide your body with the essential nutrients to function at its best and can help prevent chronic diseases. 2. Engage in regular physical activity: Exercise is crucial for maintaining strong bones, muscles, and cardiovascular health. Aim for at least 150 minutes of moderate aerobic exercise or 75 minutes of vigorous exercise each week. 3. Get enough sleep: Getting enough quality sleep is crucial for physical and mental well-being. It helps to regulate mood, improve cognitive function, and supports healthy growth and immune function. Aim for 7-9 hours of sleep each night.\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "56daad38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                text  generated\n",
      "0  Car-free cities have become a subject of incre...          1\n",
      "1  Car Free Cities  Car-free cities, a concept ga...          1\n",
      "2    A Sustainable Urban Future  Car-free cities ...          1\n",
      "3    Pioneering Sustainable Urban Living  In an e...          1\n",
      "4    The Path to Sustainable Urban Living  In an ...          1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/29145 [00:00<?, ?it/s]C:\\Users\\ssit5\\AppData\\Local\\Temp\\ipykernel_5224\\443312697.py:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  text = torch.tensor(text).to(device)\n",
      "100%|██████████| 29145/29145 [04:24<00:00, 110.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 76.65%\n",
      "Predictions\n",
      "(array([0, 1]), array([13548, 15597], dtype=int64))\n",
      "Labels\n",
      "(array([0, 1]), array([17508, 11637], dtype=int64))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "# Testing on essay data from https://www.kaggle.com/datasets/sunilthite/llm-detect-ai-generated-text-dataset\n",
    "essay_data = pd.read_csv(\"datasets/Training_Essay_Data.csv\")\n",
    "# First column is the essay text, second column is the label, 1 if AI generated, 0 if human generated\n",
    "print(essay_data.head())\n",
    "# Predict on all essays\n",
    "predictions = []\n",
    "labels = []\n",
    "for row in tqdm(essay_data.iterrows(), total=essay_data.shape[0]):\n",
    "    text = row[1][0]\n",
    "    label = row[1][1]\n",
    "    labels.append(label)\n",
    "    prediction = predict(text)\n",
    "    predictions.append(prediction)\n",
    "predictions = np.array(predictions)\n",
    "labels = np.array(labels)\n",
    "accuracy = np.mean(predictions == labels)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100))\n",
    "\n",
    "# Show distribution of predictions and labels\n",
    "print(\"Predictions\")\n",
    "print(np.unique(predictions, return_counts=True))\n",
    "print(\"Labels\")\n",
    "print(np.unique(labels, return_counts=True))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
