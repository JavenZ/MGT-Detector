{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4a5ad83f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import keras\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import TextVectorization\n",
    "from keras.models import Sequential\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "640fc742",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Download dataset SubtaskB.jsonl from \n",
    "https://github.com/mbzuai-nlp/M4GT-Bench.\n",
    "\"\"\"\n",
    "DATA_PATH = \"C:/Users/Admin/Desktop/cse847_proj/SubtaskB.jsonl\"\n",
    "\n",
    "# initialize dataframe\n",
    "df = pd.read_json(DATA_PATH, lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cbb3381e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "source\n",
      "wikihow      23556\n",
      "reddit       20999\n",
      "outfox       20999\n",
      "arxiv        20998\n",
      "wikipedia    19368\n",
      "peerread     16891\n",
      "Name: count, dtype: int64\n",
      "\n",
      "model\n",
      "bloomz           17332\n",
      "human            17179\n",
      "chatGPT          16892\n",
      "cohere           16678\n",
      "gpt4             14344\n",
      "davinci          14340\n",
      "dolly            14046\n",
      "gpt-3.5-turbo     6000\n",
      "davinci-003       3000\n",
      "dolly-v2-12b      3000\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df.source.value_counts())\n",
    "print()\n",
    "print(df.model.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d028b763",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 1 0 3 5 4 6]\n"
     ]
    }
   ],
   "source": [
    "print(df.label.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cbf69435",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>We consider a system of many polymers in solut...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>We present a catalog of 66 YSOs in the Serpens...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Spectroscopic Observations of the Intermediate...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>We present a new class of stochastic Lie group...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ALMA as the ideal probe of the solar chromosph...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122806</th>\n",
       "      <td>Title: The Unsung Heroes: Seagoing Cowboys and...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122807</th>\n",
       "      <td>Title: The Benefits of Autonomy: Student-led P...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122808</th>\n",
       "      <td>The Electoral College system, established by t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122809</th>\n",
       "      <td>In the ever-evolving landscape of education, c...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122810</th>\n",
       "      <td>When faced with critical decisions, the wise o...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>122811 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text  label\n",
       "0       We consider a system of many polymers in solut...      2\n",
       "1       We present a catalog of 66 YSOs in the Serpens...      2\n",
       "2       Spectroscopic Observations of the Intermediate...      2\n",
       "3       We present a new class of stochastic Lie group...      2\n",
       "4       ALMA as the ideal probe of the solar chromosph...      2\n",
       "...                                                   ...    ...\n",
       "122806  Title: The Unsung Heroes: Seagoing Cowboys and...      0\n",
       "122807  Title: The Benefits of Autonomy: Student-led P...      0\n",
       "122808  The Electoral College system, established by t...      0\n",
       "122809  In the ever-evolving landscape of education, c...      0\n",
       "122810  When faced with critical decisions, the wise o...      0\n",
       "\n",
       "[122811 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['text', 'label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5e8472a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Pre-process dataframe.\n",
    "\"\"\"\n",
    "MAX_VOCAB = 10_000\n",
    "MAX_LENGTH = 200\n",
    "\n",
    "# init text vectorizer\n",
    "vectorize_layer = TextVectorization(\n",
    "    max_tokens=MAX_VOCAB,\n",
    "    standardize='lower_and_strip_punctuation',\n",
    "    split='whitespace',\n",
    "    ngrams=None,\n",
    "    output_mode='int',\n",
    "    output_sequence_length=MAX_LENGTH,\n",
    "    pad_to_max_tokens=False,\n",
    "    vocabulary=None,\n",
    "    idf_weights=None,\n",
    "    sparse=False,\n",
    "    ragged=False,\n",
    "    encoding='utf-8',\n",
    "    name=None,\n",
    ")\n",
    "\n",
    "# create vocabulary\n",
    "vectorize_layer.adapt(df['text'])\n",
    "vocab = vectorize_layer.get_vocabulary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e8f5cff1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(122811, 200) (122811,)\n"
     ]
    }
   ],
   "source": [
    "# vectorize text data (in subsets for memory constraints)\n",
    "X = []\n",
    "y = df['label']\n",
    "\n",
    "subset_size = df.shape[0] // 100\n",
    "for i in range(0, df.shape[0], subset_size):\n",
    "    subset = df['text'][i : i + subset_size]\n",
    "    X.append(vectorize_layer(subset))\n",
    "\n",
    "X = np.vstack(X)\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0d5e8b5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "LSTM model generator.\n",
    "\"\"\"\n",
    "EMBEDDING_DIM = 128\n",
    "N_HIDDEN = 100\n",
    "OPTIMIZER = 'adam'\n",
    "N_CLASSES = 7\n",
    "\n",
    "def get_model(model_path=None):\n",
    "    if model_path:\n",
    "        # load existing model\n",
    "        model = keras.models.load_model(model_path)\n",
    "    else:\n",
    "        # create new model\n",
    "        model = Sequential()\n",
    "        embeddings = Embedding(\n",
    "            input_dim=MAX_VOCAB,\n",
    "            output_dim=EMBEDDING_DIM,\n",
    "        )\n",
    "        model.add(embeddings)\n",
    "        model.add(LSTM(N_HIDDEN, return_sequences=False))\n",
    "        model.add(Dense(N_CLASSES)) # , activation='softmax'\n",
    "        model.compile(\n",
    "            loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "            optimizer=OPTIMIZER,\n",
    "            metrics=['accuracy']\n",
    "        )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4d605323",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m270s\u001b[0m 164ms/step - accuracy: 0.3560 - loss: 1.6396\n",
      "Epoch 2/25\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m289s\u001b[0m 177ms/step - accuracy: 0.6090 - loss: 1.0040\n",
      "Epoch 3/25\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m291s\u001b[0m 178ms/step - accuracy: 0.7901 - loss: 0.5913\n",
      "Epoch 4/25\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m296s\u001b[0m 182ms/step - accuracy: 0.8697 - loss: 0.3729\n",
      "Epoch 5/25\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m278s\u001b[0m 170ms/step - accuracy: 0.9132 - loss: 0.2595\n",
      "Epoch 6/25\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m265s\u001b[0m 162ms/step - accuracy: 0.9397 - loss: 0.1825\n",
      "Epoch 7/25\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m264s\u001b[0m 162ms/step - accuracy: 0.9612 - loss: 0.1223\n",
      "Epoch 8/25\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m263s\u001b[0m 161ms/step - accuracy: 0.9745 - loss: 0.0823\n",
      "Epoch 9/25\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m262s\u001b[0m 161ms/step - accuracy: 0.9823 - loss: 0.0592\n",
      "Epoch 10/25\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m261s\u001b[0m 160ms/step - accuracy: 0.9862 - loss: 0.0449\n",
      "Epoch 11/25\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m259s\u001b[0m 159ms/step - accuracy: 0.9899 - loss: 0.0343\n",
      "Epoch 12/25\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m259s\u001b[0m 159ms/step - accuracy: 0.9923 - loss: 0.0259\n",
      "Epoch 13/25\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m262s\u001b[0m 161ms/step - accuracy: 0.9924 - loss: 0.0239\n",
      "Epoch 14/25\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m263s\u001b[0m 161ms/step - accuracy: 0.9940 - loss: 0.0195\n",
      "Epoch 15/25\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m265s\u001b[0m 162ms/step - accuracy: 0.9947 - loss: 0.0178\n",
      "Epoch 16/25\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m265s\u001b[0m 162ms/step - accuracy: 0.9950 - loss: 0.0161\n",
      "Epoch 17/25\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m266s\u001b[0m 163ms/step - accuracy: 0.9957 - loss: 0.0142\n",
      "Epoch 18/25\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m268s\u001b[0m 164ms/step - accuracy: 0.9947 - loss: 0.0161\n",
      "Epoch 19/25\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m267s\u001b[0m 164ms/step - accuracy: 0.9964 - loss: 0.0118\n",
      "Epoch 20/25\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m262s\u001b[0m 161ms/step - accuracy: 0.9965 - loss: 0.0111\n",
      "Epoch 21/25\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m258s\u001b[0m 158ms/step - accuracy: 0.9967 - loss: 0.0110\n",
      "Epoch 22/25\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m254s\u001b[0m 156ms/step - accuracy: 0.9966 - loss: 0.0115\n",
      "Epoch 23/25\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m255s\u001b[0m 157ms/step - accuracy: 0.9969 - loss: 0.0100\n",
      "Epoch 24/25\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m258s\u001b[0m 158ms/step - accuracy: 0.9977 - loss: 0.0083\n",
      "Epoch 25/25\n",
      "\u001b[1m1632/1632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m261s\u001b[0m 160ms/step - accuracy: 0.9959 - loss: 0.0129\n",
      "Accuracy: 80.22%\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Train and evaluate model.\n",
    "\"\"\"\n",
    "# create new model\n",
    "model = get_model()\n",
    "\n",
    "# create data splits\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X,\n",
    "    y,\n",
    "    test_size=0.15,\n",
    "    random_state=777,\n",
    ")\n",
    "\n",
    "# train the model\n",
    "model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    epochs=25,\n",
    "    batch_size=64\n",
    ")\n",
    "\n",
    "# final evaluation of the model\n",
    "scores = model.evaluate(\n",
    "    X_test,\n",
    "    y_test,\n",
    "    verbose=0\n",
    ")\n",
    "accuracy = scores[1]\n",
    "\n",
    "# report results\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100))\n",
    "\n",
    "# save model\n",
    "model.save(\"models/taskB_lstm.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a8dae301",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
