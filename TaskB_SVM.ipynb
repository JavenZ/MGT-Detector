{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "be53685c-ebbb-4514-819b-76e4537bd7df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from gensim.models import Word2Vec\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import svm\n",
    "from tqdm import tqdm\n",
    "from keras.preprocessing import sequence\n",
    "from sklearn.decomposition import PCA\n",
    "from nltk.probability import FreqDist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c912d1c2-1c95-41b5-9a1a-b6358427c3ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Utility functions.\n",
    "\"\"\"\n",
    "def f1_score(tp, fp, fn):\n",
    "    return (2 * tp) / (2 * tp + fp + fn)\n",
    "\n",
    "def precision_score(tp, fp):\n",
    "    return tp / (tp + fp)\n",
    "\n",
    "def accuracy_score(tp, fp, tn, fn):\n",
    "    return (tp + tn) / (tp + fp + tn + fn)\n",
    "\n",
    "def recall_score(tp, fn):\n",
    "    return tp / (tp + fn)\n",
    "\n",
    "def flatten(matrix):\n",
    "    flat_list = []\n",
    "    for row in matrix:\n",
    "        flat_list += row\n",
    "    return flat_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b2b0f70a-8209-4c18-87b9-bd74e074d44e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                     text  label  \\\n",
      "0       We consider a system of many polymers in solut...      2   \n",
      "1       We present a catalog of 66 YSOs in the Serpens...      2   \n",
      "2       Spectroscopic Observations of the Intermediate...      2   \n",
      "3       We present a new class of stochastic Lie group...      2   \n",
      "4       ALMA as the ideal probe of the solar chromosph...      2   \n",
      "...                                                   ...    ...   \n",
      "122806  Title: The Unsung Heroes: Seagoing Cowboys and...      0   \n",
      "122807  Title: The Benefits of Autonomy: Student-led P...      0   \n",
      "122808  The Electoral College system, established by t...      0   \n",
      "122809  In the ever-evolving landscape of education, c...      0   \n",
      "122810  When faced with critical decisions, the wise o...      0   \n",
      "\n",
      "                model  \n",
      "0              cohere  \n",
      "1              cohere  \n",
      "2              cohere  \n",
      "3              cohere  \n",
      "4              cohere  \n",
      "...               ...  \n",
      "122806  gpt-3.5-turbo  \n",
      "122807  gpt-3.5-turbo  \n",
      "122808  gpt-3.5-turbo  \n",
      "122809  gpt-3.5-turbo  \n",
      "122810  gpt-3.5-turbo  \n",
      "\n",
      "[122811 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Download dataset SubtaskA.jsonl from \n",
    "https://github.com/mbzuai-nlp/M4GT-Bench.\n",
    "\"\"\"\n",
    "DATA_PATH = \"C:/Users/Admin/Desktop/cse847_proj/SubtaskB.jsonl\"\n",
    "\n",
    "# initialize dataset\n",
    "df = pd.read_json(DATA_PATH, lines=True)\n",
    "df = df[['text', 'label', 'model']]\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7f35d370-6388-4637-9942-df3602f9dfe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Evaluate model using count/TFIDF vectorization.\n",
    "\"\"\"\n",
    "def run_cv(model, X, y, count_vectorizer, tfidf_transformer=None):\n",
    "    results = []\n",
    "    k_fold = KFold(n_splits=K_FOLDS, shuffle=True, random_state=777)\n",
    "    for train, test in tqdm(k_fold.split(X, y)):\n",
    "        # split fold into training & testing sets\n",
    "        X_train, y_train, X_test, y_test = X[train], y[train], X[test], y[test]\n",
    "\n",
    "        # fit & transform data sets\n",
    "        print(\"Count vectorizing...\")\n",
    "        X_train = count_vectorizer.fit_transform(X_train)\n",
    "        X_test = count_vectorizer.transform(X_test)\n",
    "\n",
    "        if tfidf_transformer:\n",
    "            print(\"TFIDF transforming...\")\n",
    "            X_train = tfidf_transformer.fit_transform(X_train)\n",
    "            X_test = tfidf_transformer.transform(X_test)\n",
    "\n",
    "        # train the model\n",
    "        print(\"Fitting the model...\")\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        # test the model\n",
    "        print(\"Predicting the model...\")\n",
    "        y_hat = model.predict(X_test)\n",
    "\n",
    "        # evaluate the model\n",
    "        results.append({\n",
    "            'accuracy': metric.compute(predictions=y_hat, references=y_test),\n",
    "        })        \n",
    "\n",
    "    # analyze the run results\n",
    "    results_df = pd.DataFrame.from_records(results).mean()\n",
    "\n",
    "    return results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86521a90-fd6a-485b-b62f-fdc508bb98c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count vectorizing...\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Train and evaluate SVM classifier model using count/TFIDF vectorization.\n",
    "\"\"\"\n",
    "# consts\n",
    "MAX_FEATURES = 3000\n",
    "K_FOLDS = 3\n",
    "MIN_DF = 2\n",
    "MAX_DF = 0.7\n",
    "NGRAM_RANGE = (1, 1)\n",
    "ANALYZER = 'word'\n",
    "\n",
    "# init model\n",
    "model = svm.SVC(\n",
    "    verbose=True,\n",
    "    max_iter=-1,\n",
    "    kernel='linear',\n",
    ")\n",
    "\n",
    "# define metric\n",
    "metric = evaluate.load(\"accuracy\")\n",
    "\n",
    "# load the data set\n",
    "X = np.array(df.text)\n",
    "y = np.array(df.label)\n",
    "\n",
    "# init vectorizer and transformer\n",
    "count_vectorizer = CountVectorizer(\n",
    "    min_df=MIN_DF,\n",
    "    max_df=MAX_DF,\n",
    "    max_features=MAX_FEATURES,\n",
    "    tokenizer=word_tokenize,\n",
    "    token_pattern=None,\n",
    "    ngram_range=NGRAM_RANGE,\n",
    "    # strip_accents=STRIP_ACCENTS,\n",
    "    # stop_words=STOP_WORDS,\n",
    ")\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "\n",
    "# run cross validation\n",
    "results = run_cv(model, X, y, count_vectorizer, tfidf_transformer)\n",
    "print(f\"# model={model}, k_folds={K_FOLDS}, max_features={MAX_FEATURES}, min_df={MIN_DF}, max_df={MAX_DF}, \"\n",
    "          f\"ngram_range={NGRAM_RANGE}\\n{results}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81de8d01",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
