{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "be53685c-ebbb-4514-819b-76e4537bd7df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "# from datasets import load_dataset, Dataset, DatasetDict\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from gensim.models import Word2Vec\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import svm\n",
    "from tqdm import tqdm\n",
    "from keras.preprocessing import sequence\n",
    "from sklearn.decomposition import PCA\n",
    "from nltk.probability import FreqDist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c912d1c2-1c95-41b5-9a1a-b6358427c3ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Utility functions.\n",
    "\"\"\"\n",
    "def f1_score(tp, fp, fn):\n",
    "    return (2 * tp) / (2 * tp + fp + fn)\n",
    "\n",
    "def precision_score(tp, fp):\n",
    "    return tp / (tp + fp)\n",
    "\n",
    "def accuracy_score(tp, fp, tn, fn):\n",
    "    return (tp + tn) / (tp + fp + tn + fn)\n",
    "\n",
    "def recall_score(tp, fn):\n",
    "    return tp / (tp + fn)\n",
    "\n",
    "def flatten(matrix):\n",
    "    flat_list = []\n",
    "    for row in matrix:\n",
    "        flat_list += row\n",
    "    return flat_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b2b0f70a-8209-4c18-87b9-bd74e074d44e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                     text  label   model\n",
      "0       We consider a system of many polymers in solut...      1  cohere\n",
      "1       We present a catalog of 66 YSOs in the Serpens...      1  cohere\n",
      "2       Spectroscopic Observations of the Intermediate...      1  cohere\n",
      "3       We present a new class of stochastic Lie group...      1  cohere\n",
      "4       ALMA as the ideal probe of the solar chromosph...      1  cohere\n",
      "...                                                   ...    ...     ...\n",
      "152804   The main results presented in this dissertati...      0   human\n",
      "152805   Fine-grained sketch-based image retrieval (FG...      0   human\n",
      "152806   We present the derivation of the NNLO two-par...      0   human\n",
      "152807   The principle of optimism in the face of unce...      0   human\n",
      "152808   We consider the setting of prediction with ex...      0   human\n",
      "\n",
      "[152809 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Download dataset SubtaskA.jsonl from \n",
    "https://github.com/mbzuai-nlp/M4GT-Bench.\n",
    "\"\"\"\n",
    "DATA_PATH = \"C:/Users/Admin/Desktop/cse847_proj/SubtaskA.jsonl\"\n",
    "\n",
    "# initialize dataset\n",
    "df = pd.read_json(DATA_PATH, lines=True)\n",
    "df = df[['text', 'label', 'model']]\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7f35d370-6388-4637-9942-df3602f9dfe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Evaluate model using count/TFIDF vectorization.\n",
    "\"\"\"\n",
    "def run_cv(model, X, y, count_vectorizer, tfidf_transformer=None):\n",
    "    results = []\n",
    "    k_fold = KFold(n_splits=K_FOLDS, shuffle=True, random_state=777)\n",
    "    for train, test in tqdm(k_fold.split(X, y)):\n",
    "        # split fold into training & testing sets\n",
    "        X_train, y_train, X_test, y_test = X[train], y[train], X[test], y[test]\n",
    "\n",
    "        # fit & transform data sets\n",
    "        print(\"Count vectorizing...\")\n",
    "        X_train = count_vectorizer.fit_transform(X_train)\n",
    "        X_test = count_vectorizer.transform(X_test)\n",
    "\n",
    "        if tfidf_transformer:\n",
    "            print(\"TFIDF transforming...\")\n",
    "            X_train = tfidf_transformer.fit_transform(X_train)\n",
    "            X_test = tfidf_transformer.transform(X_test)\n",
    "\n",
    "        # train the model\n",
    "        print(\"Fitting the model...\")\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        # test the model\n",
    "        print(\"Predicting the model...\")\n",
    "        y_hat = model.predict(X_test)\n",
    "\n",
    "        # evaluate the model\n",
    "        tn, fp, fn, tp = confusion_matrix(y_test, y_hat).ravel()\n",
    "        results.append({\n",
    "            'accuracy': accuracy_score(tp=tp, fp=fp, tn=tn, fn=fn),\n",
    "            'recall': recall_score(tp=tp, fn=fn),\n",
    "            'precision': precision_score(tp=tp, fp=fp),\n",
    "            'f1': f1_score(tp=tp, fp=fp, fn=fn),\n",
    "        })\n",
    "\n",
    "    # analyze the run results\n",
    "    results_df = pd.DataFrame.from_records(results).mean()\n",
    "\n",
    "    return results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "86521a90-fd6a-485b-b62f-fdc508bb98c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count vectorizing...\n",
      "TFIDF transforming...\n",
      "Fitting the model...\n",
      "[LibSVM]...................................................*...........................................*......................*.*\n",
      "optimization finished, #iter = 116277\n",
      "obj = -27890.634461, rho = 2.379204\n",
      "nSV = 31663, nBSV = 29212\n",
      "Total nSV = 31663\n",
      "Predicting the model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [1:22:04, 4924.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count vectorizing...\n",
      "TFIDF transforming...\n",
      "Fitting the model...\n",
      "[LibSVM]....................................................*..............................................*........................*.*\n",
      "optimization finished, #iter = 122330\n",
      "obj = -28099.448361, rho = 2.310642\n",
      "nSV = 31863, nBSV = 29406\n",
      "Total nSV = 31863\n",
      "Predicting the model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2it [2:44:41, 4943.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count vectorizing...\n",
      "TFIDF transforming...\n",
      "Fitting the model...\n",
      "[LibSVM]....................................................*..........................................*....................*.*\n",
      "optimization finished, #iter = 115238\n",
      "obj = -27973.743292, rho = 2.387817\n",
      "nSV = 31719, nBSV = 29263\n",
      "Total nSV = 31719\n",
      "Predicting the model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3it [4:06:20, 4926.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# model=SVC(kernel='linear', verbose=True), k_folds=3, max_features=3000, min_df=2, max_df=0.7, ngram_range=(1, 1)\n",
      "accuracy     0.887768\n",
      "recall       0.904635\n",
      "precision    0.900156\n",
      "f1           0.902390\n",
      "dtype: float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Train and evaluate SVM classifier model using count/TFIDF vectorization.\n",
    "\"\"\"\n",
    "# consts\n",
    "MAX_FEATURES = 3000\n",
    "K_FOLDS = 3\n",
    "MIN_DF = 2\n",
    "MAX_DF = 0.7\n",
    "NGRAM_RANGE = (1, 1)\n",
    "ANALYZER = 'word'\n",
    "\n",
    "# init model\n",
    "model = svm.SVC(\n",
    "    verbose=True,\n",
    "    max_iter=-1,\n",
    "    kernel='linear',\n",
    ")\n",
    "\n",
    "# load the data set\n",
    "X = np.array(df.text)\n",
    "y = np.array(df.label)\n",
    "\n",
    "# init vectorizer and transformer\n",
    "count_vectorizer = CountVectorizer(\n",
    "    min_df=MIN_DF,\n",
    "    max_df=MAX_DF,\n",
    "    max_features=MAX_FEATURES,\n",
    "    tokenizer=word_tokenize,\n",
    "    token_pattern=None,\n",
    "    ngram_range=NGRAM_RANGE,\n",
    "    # strip_accents=STRIP_ACCENTS,\n",
    "    # stop_words=STOP_WORDS,\n",
    ")\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "\n",
    "# run cross validation\n",
    "results = run_cv(model, X, y, count_vectorizer, tfidf_transformer)\n",
    "print(f\"# model={model}, k_folds={K_FOLDS}, max_features={MAX_FEATURES}, min_df={MIN_DF}, max_df={MAX_DF}, \"\n",
    "          f\"ngram_range={NGRAM_RANGE}\\n{results}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b837263-d016-454b-b160-bcc892c0f807",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
